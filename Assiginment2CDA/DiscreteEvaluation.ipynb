{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class DictionarySizeIsNotSupported(Exception): pass\n",
    "class StringsAreDifferentLength(Exception): pass\n",
    "class OverlapSpecifiedIsNotSmallerThanWindowSize(Exception): pass\n",
    "\n",
    "\n",
    "class SAX(object):\n",
    "    \"\"\"\n",
    "    This class is for computing common things with the Symbolic\n",
    "    Aggregate approXimation method.  In short, this translates\n",
    "    a series of data to a string, which can then be compared with other\n",
    "    such strings using a lookup table.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, wordSize = 8, alphabetSize = 7, epsilon = 1e-6):\n",
    "\n",
    "        if alphabetSize < 3 or alphabetSize > 20:\n",
    "            raise DictionarySizeIsNotSupported()\n",
    "        self.aOffset = ord('a')\n",
    "        self.wordSize = wordSize\n",
    "        self.alphabetSize = alphabetSize\n",
    "        self.eps = epsilon\n",
    "        self.breakpoints = {'3' : [-0.43, 0.43],\n",
    "                            '4' : [-0.67, 0, 0.67],\n",
    "                            '5' : [-0.84, -0.25, 0.25, 0.84],\n",
    "                            '6' : [-0.97, -0.43, 0, 0.43, 0.97],\n",
    "                            '7' : [-1.07, -0.57, -0.18, 0.18, 0.57, 1.07],\n",
    "                            '8' : [-1.15, -0.67, -0.32, 0, 0.32, 0.67, 1.15],\n",
    "                            '9' : [-1.22, -0.76, -0.43, -0.14, 0.14, 0.43, 0.76, 1.22],\n",
    "                            '10': [-1.28, -0.84, -0.52, -0.25, 0, 0.25, 0.52, 0.84, 1.28],\n",
    "                            '11': [-1.34, -0.91, -0.6, -0.35, -0.11, 0.11, 0.35, 0.6, 0.91, 1.34],\n",
    "                            '12': [-1.38, -0.97, -0.67, -0.43, -0.21, 0, 0.21, 0.43, 0.67, 0.97, 1.38],\n",
    "                            '13': [-1.43, -1.02, -0.74, -0.5, -0.29, -0.1, 0.1, 0.29, 0.5, 0.74, 1.02, 1.43],\n",
    "                            '14': [-1.47, -1.07, -0.79, -0.57, -0.37, -0.18, 0, 0.18, 0.37, 0.57, 0.79, 1.07, 1.47],\n",
    "                            '15': [-1.5, -1.11, -0.84, -0.62, -0.43, -0.25, -0.08, 0.08, 0.25, 0.43, 0.62, 0.84, 1.11, 1.5],\n",
    "                            '16': [-1.53, -1.15, -0.89, -0.67, -0.49, -0.32, -0.16, 0, 0.16, 0.32, 0.49, 0.67, 0.89, 1.15, 1.53],\n",
    "                            '17': [-1.56, -1.19, -0.93, -0.72, -0.54, -0.38, -0.22, -0.07, 0.07, 0.22, 0.38, 0.54, 0.72, 0.93, 1.19, 1.56],\n",
    "                            '18': [-1.59, -1.22, -0.97, -0.76, -0.59, -0.43, -0.28, -0.14, 0, 0.14, 0.28, 0.43, 0.59, 0.76, 0.97, 1.22, 1.59],\n",
    "                            '19': [-1.62, -1.25, -1, -0.8, -0.63, -0.48, -0.34, -0.2, -0.07, 0.07, 0.2, 0.34, 0.48, 0.63, 0.8, 1, 1.25, 1.62],\n",
    "                            '20': [-1.64, -1.28, -1.04, -0.84, -0.67, -0.52, -0.39, -0.25, -0.13, 0, 0.13, 0.25, 0.39, 0.52, 0.67, 0.84, 1.04, 1.28, 1.64]\n",
    "                            }\n",
    "        self.beta = self.breakpoints[str(self.alphabetSize)]\n",
    "        self.build_letter_compare_dict()\n",
    "        self.scalingFactor = 1\n",
    "\n",
    "\n",
    "    def to_letter_rep(self, x):\n",
    "        \"\"\"\n",
    "        Function takes a series of data, x, and transforms it to a string representation\n",
    "        \"\"\"\n",
    "        (paaX, indices) = self.to_PAA(self.normalize(x))\n",
    "        self.scalingFactor = np.sqrt((len(x) * 1.0) / (self.wordSize * 1.0))\n",
    "        return (self.alphabetize(paaX), indices)\n",
    "\n",
    "    def normalize(self, x):\n",
    "        \"\"\"\n",
    "        Function will normalize an array (give it a mean of 0, and a\n",
    "        standard deviation of 1) unless it's standard deviation is below\n",
    "        epsilon, in which case it returns an array of zeros the length\n",
    "        of the original array.\n",
    "        \"\"\"\n",
    "        X = np.asanyarray(x)\n",
    "        if np.nanstd(X) < self.eps:\n",
    "            res = []\n",
    "            for entry in X:\n",
    "                if not np.isnan(entry):\n",
    "                    res.append(0)\n",
    "                else:\n",
    "                    res.append(np.nan)\n",
    "        return (X - np.nanmean(X)) / np.nanstd(X)\n",
    "\n",
    "    def to_PAA(self, x):\n",
    "        \"\"\"\n",
    "        Function performs Piecewise Aggregate Approximation on data set, reducing\n",
    "        the dimension of the dataset x to w discrete levels. returns the reduced\n",
    "        dimension data set, as well as the indices corresponding to the original\n",
    "        data for each reduced dimension\n",
    "        \"\"\"\n",
    "        n = len(x)\n",
    "        stepFloat = n/float(self.wordSize)\n",
    "        step = int(math.ceil(stepFloat))\n",
    "        frameStart = 0\n",
    "        approximation = []\n",
    "        indices = []\n",
    "        i = 0\n",
    "        while frameStart <= n-step:\n",
    "            thisFrame = np.array(x[frameStart:int(frameStart + step)])\n",
    "            approximation.append(np.mean(thisFrame))\n",
    "            indices.append((frameStart, int(frameStart + step)))\n",
    "            i += 1\n",
    "            frameStart = int(i*stepFloat)\n",
    "        return (np.array(approximation), indices)\n",
    "\n",
    "    def alphabetize(self,paaX):\n",
    "        \"\"\"\n",
    "        Converts the Piecewise Aggregate Approximation of x to a series of letters.\n",
    "        \"\"\"\n",
    "        alphabetizedX = ''\n",
    "        for i in range(0, len(paaX)):\n",
    "            letterFound = False\n",
    "            for j in range(0, len(self.beta)):\n",
    "                if np.isnan(paaX[i]):\n",
    "                    alphabetizedX += '-'\n",
    "                    letterFound = True\n",
    "                    break\n",
    "                if paaX[i] < self.beta[j]:\n",
    "                    alphabetizedX += chr(self.aOffset + j)\n",
    "                    letterFound = True\n",
    "                    break\n",
    "            if not letterFound:\n",
    "                alphabetizedX += chr(self.aOffset + len(self.beta))\n",
    "        return alphabetizedX\n",
    "\n",
    "    def compare_strings(self, sA, sB):\n",
    "        \"\"\"\n",
    "        Compares two strings based on individual letter distance\n",
    "        Requires that both strings are the same length\n",
    "        \"\"\"\n",
    "        if len(sA) != len(sB):\n",
    "            raise StringsAreDifferentLength()\n",
    "        list_letters_a = [x for x in sA]\n",
    "        list_letters_b = [x for x in sB]\n",
    "        mindist = 0.0\n",
    "        for i in range(0, len(list_letters_a)):\n",
    "            if list_letters_a[i] is not '-' and list_letters_b[i] is not '-':\n",
    "                mindist += self.compare_letters(list_letters_a[i], list_letters_b[i])**2\n",
    "        mindist = self.scalingFactor* np.sqrt(mindist)\n",
    "        return mindist\n",
    "\n",
    "    def compare_letters(self, la, lb):\n",
    "        \"\"\"\n",
    "        Compare two letters based on letter distance return distance between\n",
    "        \"\"\"\n",
    "        return self.compareDict[la+lb]\n",
    "\n",
    "    def build_letter_compare_dict(self):\n",
    "        \"\"\"\n",
    "        Builds up the lookup table to determine numeric distance between two letters\n",
    "        given an alphabet size.  Entries for both 'ab' and 'ba' will be created\n",
    "        and will have identical values.\n",
    "        \"\"\"\n",
    "\n",
    "        number_rep = range(0,self.alphabetSize)\n",
    "        letters = [chr(x + self.aOffset) for x in number_rep]\n",
    "        self.compareDict = {}\n",
    "        for i in range(0, len(letters)):\n",
    "            for j in range(0, len(letters)):\n",
    "                if np.abs(number_rep[i]-number_rep[j]) <=1:\n",
    "                    self.compareDict[letters[i]+letters[j]] = 0\n",
    "                else:\n",
    "                    high_num = np.max([number_rep[i], number_rep[j]])-1\n",
    "                    low_num = np.min([number_rep[i], number_rep[j]])\n",
    "                    self.compareDict[letters[i]+letters[j]] = self.beta[high_num] - self.beta[low_num]\n",
    "\n",
    "    def sliding_window(self, x, numSubsequences = None, overlappingFraction = None):\n",
    "        if not numSubsequences:\n",
    "            numSubsequences = 20\n",
    "        self.windowSize = int(len(x)/numSubsequences)\n",
    "        if not overlappingFraction:\n",
    "            overlappingFraction = 0.9\n",
    "        overlap = self.windowSize*overlappingFraction\n",
    "        moveSize = int(self.windowSize - overlap)\n",
    "        if moveSize < 1:\n",
    "            raise OverlapSpecifiedIsNotSmallerThanWindowSize()\n",
    "        ptr = 0\n",
    "        n = len(x)\n",
    "        windowIndices = []\n",
    "        stringRep = []\n",
    "        while ptr < n-self.windowSize+1:\n",
    "            thisSubRange = x[ptr:ptr+self.windowSize]\n",
    "            (thisStringRep,indices) = self.to_letter_rep(thisSubRange)\n",
    "            stringRep.append(thisStringRep)\n",
    "            windowIndices.append((ptr, ptr+self.windowSize))\n",
    "            ptr += moveSize\n",
    "        return (stringRep,windowIndices)\n",
    "\n",
    "    def batch_compare(self, xStrings, refString):\n",
    "        return [self.compare_strings(x, refString) for x in xStrings]\n",
    "\n",
    "    def set_scaling_factor(self, scalingFactor):\n",
    "        self.scalingFactor = scalingFactor\n",
    "\n",
    "    def set_window_size(self, windowSize):\n",
    "        self.windowSize = windowSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSetdf = pd.read_csv(\"BATADAL_dataset03.csv\", parse_dates=True, index_col='DATETIME', dayfirst=True)\n",
    "EvalSetdf=pd.read_csv(\"BATADAL_dataset04.csv\", parse_dates=True, index_col='DATETIME', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensorList=[\"L_T1\",\"L_T2\",\"L_T3\",\"L_T4\",\"L_T5\",\"L_T6\",\"L_T7\",\"F_PU1\",\"F_PU2\",\"F_PU3\",\"F_PU4\",\"F_PU5\",\"F_PU6\",\"F_PU7\",\"F_PU8\",\"F_PU9\",\"F_PU10\",\"F_PU11\",\"F_V2\",\"P_J280\",\"P_J269\",\"P_J300\",\"P_J256\",\"P_J289\",\"P_J415\",\"P_J302\",\"P_J306\",\"P_J307\",\"P_J317\",\"P_J14\",\"P_J422\"]\n",
    "AllDatesDetected=[]\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc1\\Anaconda3\\envs\\exercises_stanford\\lib\\site-packages\\ipykernel_launcher.py:80: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "for el in sensorList:\n",
    "    sensor = el\n",
    "    signal = TrainingSetdf[sensor]\n",
    "    series=pd.Series(signal)\n",
    "    s = SAX(60, 3)\n",
    "    \n",
    "    (trainString, x1Indices) = s.to_letter_rep(series)\n",
    "    \n",
    "    sensor2=\" \"+sensor\n",
    "    signalTest=EvalSetdf[sensor2]\n",
    "    seriesTest=pd.Series(signalTest)\n",
    "    s = SAX(60,3)\n",
    "    \n",
    "    (TestString, xTestIndices) = s.to_letter_rep(seriesTest)\n",
    "    \n",
    "    probabilityDict = {}\n",
    "    \n",
    "\n",
    "    for i in range(len(TestString)-1):\n",
    "        trigram=TestString[i-1:i+2]\n",
    "        if trigram not in probabilityDict:\n",
    "            count=0\n",
    "            for j in range(len(trainString)-1):\n",
    "                trainTempTrigram=trainString[j-1:j+2]\n",
    "                if trainTempTrigram==trigram and trigram!='' :\n",
    "                    count+=1\n",
    "            if trigram!='' :\n",
    "                probabilityDict[trigram]=count/(len(trainString)-3)\n",
    "    \n",
    "    \n",
    "    probabilityBigramDict = {\"ab\":0,\"ba\":0,\"aa\":0,\"bb\":0,\"ca\":0,\"cb\":0,\"cc\":0,\"ac\":0,\"bc\":0}\n",
    "    ab={\"a\":0,\"b\":0,\"c\":0}\n",
    "    ba={\"a\":0,\"b\":0,\"c\":0}\n",
    "    aa={\"a\":0,\"b\":0,\"c\":0}\n",
    "    bb={\"a\":0,\"b\":0,\"c\":0}\n",
    "    ca={\"a\":0,\"b\":0,\"c\":0}\n",
    "    cb={\"a\":0,\"b\":0,\"c\":0}\n",
    "    cc={\"a\":0,\"b\":0,\"c\":0}\n",
    "    ac={\"a\":0,\"b\":0,\"c\":0}\n",
    "    bc={\"a\":0,\"b\":0,\"c\":0}\n",
    "    for i in range(len(trainString)-1):\n",
    "        trigram=trainString[i-1:i+2]\n",
    "\n",
    "        if trigram[:2]=='ab':\n",
    "            ab[trigram[2]]+=1\n",
    "            probabilityBigramDict[trigram[:2]]+=1\n",
    "        elif trigram[:2]=='ba':\n",
    "            ba[trigram[2]]+=1\n",
    "            probabilityBigramDict[trigram[:2]]+=1\n",
    "        elif trigram[:2]=='aa':\n",
    "            aa[trigram[2]]+=1\n",
    "            probabilityBigramDict[trigram[:2]]+=1\n",
    "        elif trigram[:2]=='bb':\n",
    "            bb[trigram[2]]+=1\n",
    "            probabilityBigramDict[trigram[:2]]+=1\n",
    "        elif trigram[:2]=='ca':\n",
    "            ca[trigram[2]]+=1\n",
    "            probabilityBigramDict[trigram[:2]]+=1\n",
    "        elif trigram[:2]=='cb':\n",
    "            cb[trigram[2]]+=1\n",
    "            probabilityBigramDict[trigram[:2]]+=1\n",
    "        elif trigram[:2]=='cc':\n",
    "            cc[trigram[2]]+=1\n",
    "            probabilityBigramDict[trigram[:2]]+=1\n",
    "        elif trigram[:2]=='ac':\n",
    "            ac[trigram[2]]+=1\n",
    "            probabilityBigramDict[trigram[:2]]+=1\n",
    "        elif trigram[:2]=='bc':\n",
    "            bc[trigram[2]]+=1\n",
    "            probabilityBigramDict[trigram[:2]]+=1\n",
    "\n",
    "    TransitionProbabilityDict={\"ab\":ab,\"ba\":ba,\"aa\":aa,\"bb\":bb,\"ca\":ca,\"cb\":cb,\"cc\":cc,\"ac\":ac,\"bc\":bc}\n",
    "    \n",
    "    for key,dic in TransitionProbabilityDict.items():\n",
    "        total = sum(dic.values(), 0.0)\n",
    "        if(total!=0):\n",
    "            dic = {k: v / total for k, v in dic.items()}\n",
    "            TransitionProbabilityDict[key]=dic\n",
    "    \n",
    "    total = sum(probabilityBigramDict.values(), 0.0)\n",
    "    try:\n",
    "        probabilityBigramDict = {k: v / total for k, v in probabilityBigramDict.items()}\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    TestTrigramProbs={}\n",
    "    Anomalyindex=[]\n",
    "    counter=0\n",
    "    for i in range(1,len(TestString)-1):\n",
    "        trigram=TestString[i-1:i+2]\n",
    "\n",
    "        transition=TransitionProbabilityDict.get(trigram[:2],{})\n",
    "        proba=probabilityBigramDict.get(trigram[:2])*transition.get(trigram[2])\n",
    "        if(proba==0):\n",
    "            Anomalyindex.append(i-1)\n",
    "            counter+=1\n",
    "        if trigram not in TestTrigramProbs:\n",
    "            TestTrigramProbs[trigram]=proba\n",
    "            \n",
    "            \n",
    "            \n",
    "    localtp=0\n",
    "    localfp=0\n",
    "    for el in Anomalyindex:\n",
    "\n",
    "        for dateIndex in range(xTestIndices[el][0],xTestIndices[el][1]):\n",
    "            date = EvalSetdf.index[dateIndex].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            if date not in AllDatesDetected:\n",
    "                AllDatesDetected.append(date)\n",
    "               \n",
    "            if EvalSetdf.loc[date][43]==1:\n",
    "                tp+=1\n",
    "                localtp+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "                localfp+=1\n",
    "    fn+=(219-localtp)\n",
    "tn=(len(EvalSetdf)*31-tp-fp-fn)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737\n",
      "3603\n",
      "5395\n",
      "119752\n"
     ]
    }
   ],
   "source": [
    "    print(tp)\n",
    "    print(fp)\n",
    "    print(fn)\n",
    "    print(tn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.05\n",
      "Precision: 16.98\n",
      "Recall: 12.02\n",
      "F_score: 14.08\n"
     ]
    }
   ],
   "source": [
    "Accuracy=(tp+tn)/(tp+tn+fp+fn)*100\n",
    "Precision=tp / (tp + fp)*100\n",
    "Recall = tp / (tp + fn)*100\n",
    "F_score = 2*tp /(2*tp + fp + fn)*100\n",
    "print(\"Accuracy:\",\"%.2f\" % Accuracy)\n",
    "print(\"Precision:\",\"%.2f\" % Precision)\n",
    "print(\"Recall:\", \"%.2f\" %Recall)\n",
    "print(\"F_score:\",\"%.2f\" % F_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('DiscreteDates.pickle', 'wb') as handle:\n",
    "    pickle.dump(AllDatesDetected, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
